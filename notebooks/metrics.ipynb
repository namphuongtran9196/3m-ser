{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuhaku/mambaforge-pypy3/envs/3m-ser/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import sys\n",
    "\n",
    "lib_path = os.path.abspath(\"\").replace(\"notebooks\", \"src\")\n",
    "sys.path.append(lib_path)\n",
    "\n",
    "import torch\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score,confusion_matrix, f1_score, precision_score, recall_score\n",
    "from transformers import BertTokenizer\n",
    "from data.dataloader import build_train_test_dataset\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from models import networks\n",
    "from transformers import BertTokenizer, RobertaTokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def calculate_accuracy(y_pred, y_true):\n",
    "    class_weights = {cls: 1.0/count for cls, count in Counter(y_true).items()}\n",
    "    wa = balanced_accuracy_score(y_true, y_pred, sample_weight=[class_weights[cls] for cls in y_true])\n",
    "    ua = accuracy_score(y_true, y_pred)\n",
    "    return ua, wa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(opt, checkpoint_path, all_state_dict=True):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    network = getattr(networks, opt.model_type)(opt)\n",
    "    network.to(device)\n",
    "\n",
    "    # Build dataset\n",
    "    _, test_ds = build_train_test_dataset(opt)\n",
    "    weight = torch.load(checkpoint_path, map_location=torch.device(device))\n",
    "    if all_state_dict:\n",
    "        weight = weight['state_dict_network']\n",
    "    else:\n",
    "        weight = weight.state_dict()\n",
    "    \n",
    "    network.load_state_dict(weight)\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    y_actu=[]\n",
    "    y_pred=[]\n",
    "\n",
    "    for every_test_list in tqdm(test_ds):\n",
    "        input_ids, audio, label = every_test_list\n",
    "        input_ids = input_ids.to(device)\n",
    "        audio = audio.to(device)\n",
    "        label = label.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = network(input_ids,audio)[0]\n",
    "            _, preds = torch.max(output, 1)\n",
    "            y_actu.append(label.detach().cpu().numpy()[0])\n",
    "            y_pred.append(preds.detach().cpu().numpy()[0])\n",
    "    bacc = balanced_accuracy_score(y_actu, y_pred)\n",
    "    print(\"Balanced Accuracy: \", bacc)\n",
    "    ua, wa = calculate_accuracy(y_actu, y_pred)\n",
    "    print(\"Unweighted Accuracy: \", ua)\n",
    "    print(\"Weighted Accuracy: \", wa)\n",
    "    ua_f1 = f1_score(y_actu, y_pred, average='macro')\n",
    "    # mean_f1 = np.mean(f1_score(y_actu, y_pred, average=None))\n",
    "    # w_f1 = f1_score(y_actu, y_pred, average='weighted')\n",
    "    # f1 = f1_score(y_actu, y_pred, average='micro')\n",
    "    # print(\"Micro F1: \", f1)\n",
    "    print(\"Macro F1: \", ua_f1)\n",
    "    # print(\"Weighted F1: \", w_f1)\n",
    "    # print(\"Mean F1:\", mean_f1)\n",
    "    # ua_precision = precision_score(y_actu, y_pred, average='macro')\n",
    "    # w_precision = precision_score(y_actu, y_pred, average='weighted')\n",
    "    # precision = precision_score(y_actu, y_pred, average='micro')\n",
    "    # mean_precision = np.mean(precision_score(y_actu, y_pred, average=None))\n",
    "    # print(\"Micro Precision: \", precision)\n",
    "    # print(\"Macro Precision: \", ua_precision)\n",
    "    # print(\"Weighted Precision: \", w_precision)\n",
    "    # print(\"Mean precision:\", mean_precision)\n",
    "    # ua_recall = recall_score(y_actu, y_pred, average='macro')\n",
    "    # w_recall = recall_score(y_actu, y_pred, average='weighted')\n",
    "    # recall = recall_score(y_actu, y_pred, average='micro')\n",
    "    # print(\"Micro Recall: \", recall)\n",
    "    # print(\"Macro Recall: \", ua_recall)\n",
    "    # print(\"Weighted Recall: \", w_recall)\n",
    "    \n",
    "    # cm = confusion_matrix(y_actu, y_pred)\n",
    "    # print(\"Confusion Matrix: \\n\", cm)\n",
    "    # cmn = (cm.astype('float') / cm.sum(axis=1)[:, np.newaxis])*100\n",
    "\n",
    "    # ax = plt.subplots(figsize=(8, 5.5))[1]\n",
    "    # sns.heatmap(cmn, cmap='YlOrBr', annot=True, square=True, linecolor='black', linewidths=0.75, ax = ax, fmt = '.2f', annot_kws={'size': 16})\n",
    "    # ax.set_xlabel('Predicted', fontsize=18, fontweight='bold')\n",
    "    # ax.xaxis.set_label_position('bottom')\n",
    "    # ax.xaxis.set_ticklabels([\"Anger\", \"Happiness\", \"Sadness\", \"Neutral\"], fontsize=16)\n",
    "    # ax.set_ylabel('Ground Truth', fontsize=18, fontweight='bold')\n",
    "    # ax.yaxis.set_ticklabels([\"Anger\", \"Happiness\", \"Sadness\", \"Neutral\"], fontsize=16)\n",
    "    # plt.tight_layout()\n",
    "    # # plt.savefig(opt.name + '.png', format='png', dpi=1200)\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_svm(opt, checkpoint_path, all_state_dict=True):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    network = getattr(networks, opt.model_type)(opt)\n",
    "    network.to(device)\n",
    "\n",
    "    # Build dataset\n",
    "    train_ds, test_ds = build_train_test_dataset(opt)\n",
    "    weight = torch.load(checkpoint_path, map_location=torch.device(device))\n",
    "    if all_state_dict:\n",
    "        weight = weight['state_dict_network']\n",
    "    else:\n",
    "        weight = weight.state_dict()\n",
    "    \n",
    "    network.load_state_dict(weight)\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    # Get train features\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    for every_train_list in tqdm(train_ds):\n",
    "        input_ids, audio, label = every_train_list\n",
    "        input_ids = input_ids.to(device)\n",
    "        audio = audio.to(device)\n",
    "        label = label.to(device)\n",
    "        with torch.no_grad():\n",
    "            feature = network(input_ids,audio)[1]\n",
    "            train_x.append(feature.detach().cpu().numpy()[0])\n",
    "            train_y.append(label.detach().cpu().numpy()[0])\n",
    "    \n",
    "    # SVM\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(train_x, train_y)\n",
    "    \n",
    "    y_actu=[]\n",
    "    y_pred=[]\n",
    "\n",
    "    for every_test_list in tqdm(test_ds):\n",
    "        input_ids, audio, label = every_test_list\n",
    "        input_ids = input_ids.to(device)\n",
    "        audio = audio.to(device)\n",
    "        label = label.to(device)\n",
    "        with torch.no_grad():\n",
    "            feature = network(input_ids,audio)[1]\n",
    "            preds = clf.predict(feature.detach().cpu().numpy())\n",
    "            y_actu.append(label.detach().cpu().numpy()[0])\n",
    "            y_pred.append(preds[0])\n",
    "    bacc = balanced_accuracy_score(y_actu, y_pred)\n",
    "    ua, wa = calculate_accuracy(y_actu, y_pred)\n",
    "    print(\"Balanced Accuracy: \", bacc)\n",
    "    print(\"Unweighted Accuracy: \", ua)\n",
    "    print(\"Weighted Accuracy: \", wa)\n",
    "    \n",
    "    ua_f1 = f1_score(y_actu, y_pred, average='macro')\n",
    "    # w_f1 = f1_score(y_actu, y_pred, average='weighted')\n",
    "    # f1 = f1_score(y_actu, y_pred, average='micro')\n",
    "    # print(\"Micro F1: \", f1)\n",
    "    print(\"Macro F1: \", ua_f1)\n",
    "    # print(\"Weighted F1: \", w_f1)\n",
    "    # ua_precision = precision_score(y_actu, y_pred, average='macro')\n",
    "    # w_precision = precision_score(y_actu, y_pred, average='weighted')\n",
    "    # precision = precision_score(y_actu, y_pred, average='micro')\n",
    "    # print(\"Micro Precision: \", precision)\n",
    "    # print(\"Macro Precision: \", ua_precision)\n",
    "    # print(\"Weighted Precision: \", w_precision)\n",
    "    # ua_recall = recall_score(y_actu, y_pred, average='macro')\n",
    "    # w_recall = recall_score(y_actu, y_pred, average='weighted')\n",
    "    # recall = recall_score(y_actu, y_pred, average='micro')\n",
    "    # print(\"Micro Recall: \", recall)\n",
    "    # print(\"Macro Recall: \", ua_recall)\n",
    "    # print(\"Weighted Recall: \", w_recall)\n",
    "    \n",
    "    # cm = confusion_matrix(y_actu, y_pred)\n",
    "    # print(\"Confusion Matrix: \\n\", cm)\n",
    "    # cmn = (cm.astype('float') / cm.sum(axis=1)[:, np.newaxis])*100\n",
    "\n",
    "    # ax = plt.subplots(figsize=(8, 5.5))[1]\n",
    "    # sns.heatmap(cmn, cmap='YlOrBr', annot=True, square=True, linecolor='black', linewidths=0.75, ax = ax, fmt = '.2f', annot_kws={'size': 16})\n",
    "    # ax.set_xlabel('Predicted', fontsize=18, fontweight='bold')\n",
    "    # ax.xaxis.set_label_position('bottom')\n",
    "    # ax.xaxis.set_ticklabels([\"Anger\", \"Happiness\", \"Sadness\", \"Neutral\"], fontsize=16)\n",
    "    # ax.set_ylabel('Ground Truth', fontsize=18, fontweight='bold')\n",
    "    # ax.yaxis.set_ticklabels([\"Anger\", \"Happiness\", \"Sadness\", \"Neutral\"], fontsize=16)\n",
    "    # plt.tight_layout()\n",
    "    # plt.savefig(opt.name + '.png', format='png', dpi=1200)\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 933/933 [01:01<00:00, 15.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy:  0.8083373125339526\n",
      "Unweighted Accuracy:  0.8027867095391211\n",
      "Weighted Accuracy:  0.8106921260324083\n",
      "Macro F1:  0.8089718416956387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from configs.base import Config\n",
    "checkpoint_path = \"/home/kuhaku/Code/EmotionClassification/code/3m-ser-private/scripts/checkpoints_drive/3M-SER_v2_roberta_wav2vec2_losses/FocalLoss_cls/20230910-235436\"\n",
    "opt_path = os.path.join(checkpoint_path,\"opt.log\")\n",
    "ckpt_path = os.path.join(checkpoint_path,\"weights/best_acc/checkpoint_0_0.pt\")\n",
    "\n",
    "opt = Config()\n",
    "\n",
    "opt.load(opt_path)\n",
    "# Set dataset path\n",
    "opt.data_root=\"/home/kuhaku/Code/EmotionClassification/code/3m-ser-private/notebooks/data/IEMOCAP/\"\n",
    "\n",
    "eval(opt, ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 3728/3728 [03:51<00:00, 16.13it/s]\n",
      "100%|██████████| 933/933 [00:59<00:00, 15.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy:  0.7884813166528788\n",
      "Unweighted Accuracy:  0.782422293676313\n",
      "Weighted Accuracy:  0.7892457206846899\n",
      "Macro F1:  0.7887573989632025\n"
     ]
    }
   ],
   "source": [
    "from configs.base import Config\n",
    "checkpoint_path = \"/home/kuhaku/Code/EmotionClassification/code/3m-ser-private/scripts/checkpoints_drive/3M-SER_v2_roberta_wav2vec2_losses/ContrastiveCenterLossSER_cls/20230910-235648\"\n",
    "opt_path = os.path.join(checkpoint_path,\"opt.log\")\n",
    "ckpt_path = os.path.join(checkpoint_path,\"weights/best_acc/checkpoint_0_0.pt\")\n",
    "\n",
    "opt = Config()\n",
    "\n",
    "opt.load(opt_path)\n",
    "# Set dataset path\n",
    "opt.data_root=\"/home/kuhaku/Code/EmotionClassification/code/3m-ser-private/notebooks/data/IEMOCAP/\"\n",
    "\n",
    "eval_svm(opt, ckpt_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
